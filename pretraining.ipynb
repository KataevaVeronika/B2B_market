{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\nfrom os import listdir\nfrom os.path import isfile, join","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/building-materials/'\nfiles = [file for file in listdir(path) if isfile(join(path, file))]","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretraining_data = ''\nfor filename in files:\n    with open(path + filename, 'r') as file:\n        full_text = file.read()\n        sentences = sent_tokenize(full_text)\n        pretraining_data += '\\n'.join(sentences) + '\\n\\n'","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/working/pretraining_data.txt', 'w') as file:\n    file.write(pretraining_data)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==1.15","execution_count":5,"outputs":[{"output_type":"stream","text":"Collecting tensorflow==1.15\n  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n\u001b[K     |████████████████████████████████| 412.3 MB 18 kB/s s eta 0:00:01\n\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\nCollecting keras-applications>=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 180 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.14.0)\nCollecting tensorboard<1.16.0,>=1.15.0\n  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 22.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.30.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (3.12.2)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.5)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\nCollecting tensorflow-estimator==1.15.1\n  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n\u001b[K     |████████████████████████████████| 503 kB 44.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (46.1.3.post20200325)\nBuilding wheels for collected packages: gast\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=1f16dacaa2338a34fad599cc438e7a994dda8eec14ce2e366e27c3a115f41624\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built gast\n\u001b[31mERROR: tensorflow-probability 0.10.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\nInstalling collected packages: keras-applications, tensorboard, tensorflow-estimator, gast, astor, tensorflow\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.2.2\n    Uninstalling tensorboard-2.2.2:\n      Successfully uninstalled tensorboard-2.2.2\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.2.0\n    Uninstalling tensorflow-estimator-2.2.0:\n      Successfully uninstalled tensorflow-estimator-2.2.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.2.0\n    Uninstalling tensorflow-2.2.0:\n      Successfully uninstalled tensorflow-2.2.0\nSuccessfully installed astor-0.8.1 gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ../input/bertsrc/","execution_count":6,"outputs":[{"output_type":"stream","text":"/kaggle/input/bertsrc\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":7,"outputs":[{"output_type":"stream","text":"CONTRIBUTING.md\t\t    optimization_test.py\r\nLICENSE\t\t\t    predicting_movie_reviews_with_bert_on_tf_hub.ipynb\r\nREADME.md\t\t    requirements.txt\r\n__init__.py\t\t    run_classifier.py\r\ncreate_pretraining_data.py  run_classifier_with_tfhub.py\r\nextract_features.py\t    run_pretraining.py\r\nmodeling.py\t\t    run_squad.py\r\nmodeling_test.py\t    sample_text.txt\r\nmultilingual.md\t\t    tokenization.py\r\noptimization.py\t\t    tokenization_test.py\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python create_pretraining_data.py \\\n    --input_file=/kaggle/working/pretraining_data.txt \\\n    --output_file=/kaggle/working/tf_examples.tfrecord \\\n    --vocab_file=/kaggle/input/sentence-ru-cased-l12-h768-a12/vocab.txt \\\n    --do_lower_case=True \\\n    --max_seq_length=128 \\\n    --max_predictions_per_seq=20 \\\n    --masked_lm_prob=0.15 \\\n    --random_seed=12345 \\\n    --dupe_factor=5","execution_count":8,"outputs":[{"output_type":"stream","text":"W1111 11:51:36.401466 139695582779200 module_wrapper.py:139] From create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n\nW1111 11:51:36.401715 139695582779200 module_wrapper.py:139] From create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n\nW1111 11:51:36.402036 139695582779200 module_wrapper.py:139] From /kaggle/input/bertsrc/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nW1111 11:51:37.085612 139695582779200 module_wrapper.py:139] From create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n\nW1111 11:51:37.086758 139695582779200 module_wrapper.py:139] From create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n\nI1111 11:51:37.089318 139695582779200 create_pretraining_data.py:446] *** Reading from input files ***\nI1111 11:51:37.089560 139695582779200 create_pretraining_data.py:448]   /kaggle/working/pretraining_data.txt\nI1111 11:51:37.302219 139695582779200 create_pretraining_data.py:457] *** Writing to output files ***\nI1111 11:51:37.302535 139695582779200 create_pretraining_data.py:459]   /kaggle/working/tf_examples.tfrecord\nW1111 11:51:37.302837 139695582779200 module_wrapper.py:139] From create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n\nI1111 11:51:37.303873 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.304160 139695582779200 create_pretraining_data.py:151] tokens: [CLS] для [MASK] ##ивания [MASK] кирпича чаще всего используют следующие виды декоративных [MASK] : анг ##об , глазур ##ь и металло ##поли ##мер ##ное [MASK] [MASK] с их помощью можно добиться практически режиссёрами оттенка кирпича . [SEP] модифика ##ци ##еи обычного листа является так называем ##ы ##и ар ##очны ##и гипс [MASK] ##тон , толщина листа которого [MASK] 6 , 5 миллиметра ##м . дан ##ны ##и тип листов используется для [MASK] ##ист ##ва ради ##альных , [MASK] ##ных , [MASK] ##ообразных форм из - за свое ##и замечательно ##и гибкости . [MASK] ##ои замысел архитектора в части устро ##ист ##ва потол ##ков может [MASK] [MASK] именно принимающий помощью этого типа . просто ##kus ##ен для изготовления различного рода декоративных конструкции , однако не обладает нес ##ущ [SEP]\nI1111 11:51:37.304404 139695582779200 create_pretraining_data.py:161] input_ids: 101 2748 103 13389 103 41833 16462 6675 17432 13958 16819 58706 103 156 14590 1702 128 107343 896 851 55775 32352 2865 2784 103 103 869 3806 10219 7021 19545 11774 69604 90315 41833 132 102 23565 1827 15034 34799 36507 4415 2306 11698 880 852 3132 107004 852 98479 103 7831 128 49738 36507 6213 103 148 128 146 52686 866 132 3813 1468 852 7222 26217 12404 2748 103 1786 7241 7809 5532 128 103 1755 128 103 42562 5093 1703 130 1758 6277 852 107268 852 119025 132 103 15484 55883 22895 845 5931 13999 1786 7241 39361 2570 5269 103 103 10140 119329 10219 4638 10298 132 12926 17982 1386 2748 26334 33985 10744 58706 19253 128 5656 1699 19479 8447 3043 102\nI1111 11:51:37.304589 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.304775 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.304922 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 2 4 12 15 24 25 32 51 54 57 71 77 80 92 101 104 105 107 113 0\nI1111 11:51:37.305113 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 27898 15373 116481 1702 38252 132 24508 68600 49738 26578 13999 108659 41251 6556 39361 6345 45762 869 78728 0\nI1111 11:51:37.305305 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.305468 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\nI1111 11:51:37.306057 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.306298 139695582779200 create_pretraining_data.py:151] tokens: [CLS] [MASK] ##и лист гипс ##окар ##тона состоит из зат ##верд ##евшего гипса с добав ##ками , [MASK] двух слоев прочно ##и [MASK] ##и [MASK] ##кокристалл \" наш \" лист - [MASK] чуть больше 91 % дву ##водного гипса , около 6 % картона и остальное - крахмал , влаг [MASK] и органическое поверхностно ##е вещество либерт благодаря своему составу гипс ##окар ##тон [MASK] к применению [SEP] керам ##ически ##и кирпич надел ##ен целым рядом неоспор ##имых преимуществ . он невероятно проч ##ен и износ ##осто ##ек , обладает высоко ##и мороз ##осто ##икос ##ть ##ю и хорош ##еи звуко [MASK] ##ци ##еи , экологи ##чен , так как изготавливается из натурального [MASK] - [MASK] , [MASK] поэтому обеспечивает весьма комфорт ##ные условия для проживания человека [MASK] [SEP]\nI1111 11:51:37.306516 139695582779200 create_pretraining_data.py:161] input_ids: 101 103 852 14327 98479 68600 17181 11806 1703 5239 9384 44407 107061 869 9791 6887 128 103 5547 45208 48916 852 103 852 103 102363 108 10189 108 14327 130 103 18836 8980 13031 114 36096 105572 107061 128 4929 148 114 104541 851 43757 130 118803 128 37559 103 851 99640 111309 842 31856 93200 11179 15008 34763 98479 68600 7831 103 861 46109 102 25052 6201 852 53575 20770 1386 60945 12286 91484 16635 11943 132 2886 59780 11560 1386 851 62768 6915 1575 128 19479 20658 852 45924 6915 55627 4099 898 851 9834 15034 61097 103 1827 15034 128 44593 17092 128 2306 2739 68404 1703 73462 103 130 103 128 103 11032 23067 15455 39843 2059 16132 2748 29948 6798 103 102\nI1111 11:51:37.306692 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.306865 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.306989 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 1 2 17 21 22 24 25 31 45 50 54 56 63 73 100 112 114 116 126 0\nI1111 11:51:37.307119 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 1468 852 851 852 80410 24305 132 3998 43757 626 842 132 50717 60945 57576 31130 46836 625 132 0\nI1111 11:51:37.307254 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.307617 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\nI1111 11:51:37.308237 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.308522 139695582779200 create_pretraining_data.py:151] tokens: [CLS] экологическая чистота , Самод токс [MASK] ингредиентов - характерные [MASK] ##ства нашего материала . существует несколько типов листов , а именно : обыч ##ны ##и , влаго ##сто ##ики ##и , огнест ##ои ##ки ##и . правда , в последнее время появилось цифрового несколько модификации , но останов ##имся мы [MASK] на перечисленных . [SEP] [MASK] [MASK] тип гипс ##окар ##тон ##ных Декларации , толщина листа составляет 12 motion 12 , 5 миллиметров , габариты [MASK] 2500 ##х ##120 ##0 и 3000 ##х [MASK] [MASK] ( мм ) . существуют [MASK] и меньше ##и толщины . [MASK] [MASK] ##ны ##и [MASK] ##окар ##тон [MASK] сокращенно - г ##кл ) для устро ##ист ##ва [MASK] , перегород ##ок , облицов ##ки колонн , устро [MASK] ##ва короб [SEP]\nI1111 11:51:37.308750 139695582779200 create_pretraining_data.py:161] input_ids: 101 86784 109291 128 90133 29179 103 97192 130 38242 103 2924 25033 20531 132 13933 5325 21150 26217 128 625 10140 156 8607 1468 852 128 107600 6779 3437 852 128 26802 15484 2237 852 132 21566 128 845 16698 3299 20444 51075 5325 27785 128 3435 11896 13457 8235 103 1469 26150 132 102 103 103 7222 98479 68600 7831 1755 74245 128 49738 36507 6637 4367 30619 4367 128 146 27932 128 88030 103 25346 884 116827 137 851 15847 884 103 103 120 9490 122 132 20114 103 851 14823 852 60278 132 103 103 1468 852 103 68600 7831 103 94183 130 847 50770 122 2748 13999 1786 7241 103 128 50191 1770 128 63363 2237 43609 128 13999 103 7241 21459 102\nI1111 11:51:37.308974 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.309240 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.309453 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 4 6 10 43 51 56 57 63 69 76 84 85 91 97 98 101 104 114 124 0\nI1111 11:51:37.309628 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 17902 4556 8305 8106 10140 852 64084 26217 130 36507 116827 137 27785 22476 8607 98479 120 14082 1786 0\nI1111 11:51:37.309808 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.309986 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.310832 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.311139 139695582779200 create_pretraining_data.py:151] tokens: [CLS] огнест ##ои ##ки ##и гипс ##окар ##тон ( г ##кл ##о ) в основном применяется для устро ##ист [MASK] короб ##ов , облицов ##ки поверхност ##еи стен и потол ##ков с большим сосредоточен ##ием инженерных сете ##и , с повышенным [MASK] требованиями по огнест ##ои ##кости конструкции , таких как [MASK] ##ничные клетки здании [MASK] немного о технологии [MASK] . [SEP] ##е ознакомиться с нею [MASK] инструкция ##х [MASK] монтаж ##у , разработанных каждым производителем , представленным на рынке строительных материалов . в кажд ##ои из них вы виноват [MASK] на ##ити деталь [MASK] рекомендации [MASK] устро ##ист ##ву практически всех типов конструкции , возможных к исполнению с применением [MASK] , а также норм ##орас ##ходы [MASK] на 1 кв . Феофил поверхност [MASK] описанных конструкции [SEP]\nI1111 11:51:37.311516 139695582779200 create_pretraining_data.py:161] input_ids: 101 26802 15484 2237 852 98479 68600 7831 120 847 50770 613 122 845 10171 22476 2748 13999 1786 103 21459 1388 128 63363 2237 33195 15034 14082 851 39361 2570 869 15906 94410 4066 40241 69758 852 128 869 69508 103 39797 1516 26802 15484 18130 19253 128 9884 2739 103 67260 22595 16572 103 17042 612 16842 103 132 102 842 43485 869 64465 103 97398 884 103 31427 876 128 58462 34217 40168 128 101448 1469 15155 29217 16135 132 845 6938 15484 1703 5768 1761 74084 103 1469 13305 64642 103 30129 103 13999 1786 18459 11774 6399 21150 19253 128 22431 861 44047 869 28405 103 128 625 3060 11082 95898 50734 103 1469 138 6603 132 70923 33195 103 61093 19253 102\nI1111 11:51:37.311800 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.312017 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.312165 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 4 19 20 41 51 55 59 66 68 69 89 90 94 96 101 110 117 122 124 0\nI1111 11:51:37.312330 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 852 7241 21459 852 23295 132 61930 845 884 1516 17530 842 2059 1516 6399 20531 16135 26168 15034 0\nI1111 11:51:37.312532 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.312663 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.313435 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.313679 139695582779200 create_pretraining_data.py:151] tokens: [CLS] как о строительном материале , написано очень много , да и говорить о нем можно бесконечно , но все [MASK] [MASK] ##но . однако нач ##нем мы с начала , то есть с истории возникновения этого уникального строительного материала . казалось , гипс ##окар ##тон был известен [MASK] всегда [MASK] но на самом [MASK] этот материал как таково ##и [MASK] изобрет ##ен только в [MASK] [MASK] века в ам ##ерик ##е , Рики придумал этот композит нек ##ии август ##ин сак ##кет . будучи [MASK] фирмы по производству [MASK] , мистер сак ##кет активно занимался поиском дополнительных [MASK] применения бумаги [MASK] производ ##имо ##и [SEP] соедин ##ив десятью слоями бумаги тонкую полоск ##у гипса , предприниматель и получил [MASK] так называемую [MASK] координирует доску \" . [SEP]\nI1111 11:51:37.313916 139695582779200 create_pretraining_data.py:161] input_ids: 101 2739 612 85133 45275 128 28780 7805 6379 128 6974 851 20821 612 4757 7021 53697 128 3435 4752 103 103 1438 132 5656 3003 5777 8235 869 8086 128 3815 6818 869 7840 27035 4638 68061 40716 20531 132 36973 128 98479 68600 7831 2067 14015 103 12929 103 3435 1469 14028 103 7011 15772 2739 97795 852 103 18086 1386 4564 845 103 103 6521 845 12065 61799 842 128 43961 48947 7011 18154 5158 1524 5098 1505 38303 34829 132 16915 103 18821 1516 22097 103 128 53925 38303 34829 13914 14274 55236 23093 103 18337 24305 103 5383 7065 852 102 9948 1581 69610 73473 24305 96690 89288 876 107061 128 21422 851 6149 103 2306 44614 103 106661 66250 108 132 102\nI1111 11:51:37.314141 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.314387 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.314553 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 20 21 48 50 52 54 60 65 66 70 73 85 89 98 101 104 119 122 123 0\nI1111 11:51:37.314710 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 17561 14806 82498 128 1469 15179 2067 11639 112855 61799 851 26973 24305 26010 128 852 11923 108 99465 0\nI1111 11:51:37.314879 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.315007 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.315694 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.315946 139695582779200 create_pretraining_data.py:151] tokens: [CLS] таким образом [MASK] облицов ##очны ##и кирпич служит для защиты и украшения [MASK] [MASK] и сооружении . [SEP] . его также называют лице ##вы [MASK] , факту [MASK] ##ным , [MASK] [MASK] либо фасад ##ным . характерными квалификационный облицов ##очного кирпича являются [MASK] прочность , мороз ##осто ##икос ##ть и цвет ##осто [MASK] ##ть , низкое влаго ##по ##гл ##ощ ##ение . на сегодняш ##нии день существует огромное [MASK] разновид ##ност ##еи облицов ##очного [MASK] . [MASK] ##ны ##и облицов ##очны [MASK] кирпич характеризуется большим разнообразием первобыт , факту ##р , цветов и оттенков . он производится в виде стандартных прямоугольник ##ов , а также клинов [MASK] ##и , [MASK] ##ленно ##и , трапеци ##евид [MASK] ##и , волн ##исто ##и , вит ##ои , со [SEP]\nI1111 11:51:37.316197 139695582779200 create_pretraining_data.py:161] input_ids: 101 11510 7363 103 63363 107004 852 53575 22618 2748 14117 851 35338 103 103 851 76360 132 102 132 2752 3060 14919 27431 9209 103 128 20615 103 2010 128 103 103 8568 29630 2010 132 66447 67045 63363 12511 41833 8729 103 51486 128 45924 6915 55627 4099 851 9542 6915 103 4099 128 61291 107600 23784 5355 4542 2011 132 1469 18071 10781 6622 13933 28126 103 22328 2008 15034 63363 12511 103 132 103 1468 852 63363 107004 103 53575 28197 15906 63077 53665 128 20615 874 128 25258 851 60436 132 2886 24050 845 7310 43713 109078 1388 128 625 3060 72954 103 852 128 103 17067 852 128 98869 10329 103 852 128 18351 34792 852 128 22556 15484 128 1580 102\nI1111 11:51:37.316465 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.316722 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.316882 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 3 13 14 25 28 31 32 38 41 43 53 69 75 77 82 87 107 110 116 0\nI1111 11:51:37.317037 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 128 9942 16572 866 874 20117 78568 43732 41833 26352 55627 9595 41833 53104 852 5093 49196 48712 1438 0\nI1111 11:51:37.317203 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.317381 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.318063 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.318383 139695582779200 create_pretraining_data.py:151] tokens: [CLS] ##ны ##и гипс ##окар ##тон [MASK] серого цвета , 774 вот следующ ##ии тип - влаго [MASK] ##ики ##и - обычно зеленого . влаго ##сто ##ики ##и гипс [MASK] ТЭФИ [MASK] сокращенно - г ##кл ##в ) выпускается то ##и же [MASK] листов [MASK] что и обыч ##ны [MASK] стен [MASK] ##и , то ##щин ##ои 12 , 5 ( мм ) , [SEP] , потол ##ков , перегород ##ок , оконных [MASK] ##емногу ##ных откос ##ов в [MASK] стенах , везде двигателях где есть влаг ##а [MASK] где воздух может быть насыщ ##ен водяным ##и парами , а именно : в ##изу ##х , ванны ##х комнатах , при [MASK] ##ке внутренних стен и устро ##ист ##ве самых разных подвес ##ных потол ##ков в помещениях [SEP]\nI1111 11:51:37.318641 139695582779200 create_pretraining_data.py:161] input_ids: 101 1468 852 98479 68600 7831 103 40570 13876 128 68180 19030 6508 1524 7222 130 107600 103 3437 852 130 11552 83537 132 107600 6779 3437 852 98479 103 84501 103 94183 130 847 50770 846 122 45624 3815 852 3629 103 26217 103 1997 851 8607 1468 103 14082 103 852 128 3815 101590 15484 4367 128 146 120 9490 122 128 102 128 39361 2570 128 50191 1770 128 115783 103 105560 1755 110677 1388 845 103 32697 128 40042 82000 4206 6818 37559 626 103 4206 12958 5269 6345 31829 1386 105046 852 50440 128 625 10140 156 845 27964 884 128 96188 884 82122 128 2790 103 3231 14263 14082 851 13999 1786 9078 10586 12246 59060 1755 39361 2570 845 39769 102\nI1111 11:51:37.318854 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.319077 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.319234 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 6 10 17 29 30 31 42 44 49 51 73 74 79 83 88 103 108 111 113 0\nI1111 11:51:37.319404 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 24050 625 6779 68600 7831 120 60278 128 852 9127 851 39339 84469 128 128 60111 82122 63363 14263 0\nI1111 11:51:37.319579 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.319725 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.320392 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.320583 139695582779200 create_pretraining_data.py:151] tokens: [CLS] особую популярность у [MASK] ##еле ##и [MASK] ##окар ##тон получил за удобство при использовании , возможность сокращения объемов \" мокр ##ых [MASK] процессов [MASK] отделке [MASK] , за снижение времени производства работ , за Digital ##ичность материала . [SEP] полюбил ##ся он и заказчикам [MASK] [SEP]\nI1111 11:51:37.320799 139695582779200 create_pretraining_data.py:161] input_ids: 101 38712 20829 875 103 8151 852 103 68600 7831 6149 1758 103866 2790 21964 128 10796 29622 51107 108 71308 2558 103 21641 103 89660 103 128 1758 23391 6651 11644 3234 128 1758 14340 23933 20531 132 102 96859 1523 2886 851 95117 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.321003 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.321196 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.321381 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 4 7 22 24 26 35 45 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.321533 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 50967 98479 108 2790 26485 9980 132 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.321678 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\nI1111 11:51:37.321828 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.322450 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.322699 139695582779200 create_pretraining_data.py:151] tokens: [CLS] [MASK] [MASK] . кирпич силикат ##ны ##ив наше время кирпич – это очень востребован ##ны ##и , практ ##ичны ##и , проч ##ны ##и , долгов ##еч [MASK] ##и и в [MASK] время недорог [MASK] строитель ##ны ##и материал с [MASK] ##и эксплуата ##ционными характеристиками и многовек ##ово ##и [MASK] ##еи , котор ##ы ##и преступной чаще используют в [MASK] строительстве здании и сооружении [SEP] с [MASK] [MASK] уверенностью [MASK] сказать , что здания и сооружения , построенные из кирпича , имеют очень красив ##ы ##и [MASK] ##нии вид , а [MASK] обеспечивают уют и комфорт ##ные условия проживания . се [MASK] довольно часто при проведении различных строительных работ используют три разновидности Siege – силикат ##ны ##и , керам ##ически ##и [MASK] облицов ##очны ##и . [SEP]\nI1111 11:51:37.322951 139695582779200 create_pretraining_data.py:161] input_ids: 101 103 103 132 53575 87129 1468 1581 32341 3299 53575 1022 3998 7805 113256 1468 852 128 8251 33241 852 128 11560 1468 852 128 23802 2311 103 852 851 845 103 3299 73239 103 7478 1468 852 15772 869 103 852 18981 36988 50082 851 81972 9127 852 103 15034 128 2075 880 852 36436 16462 17432 845 103 19789 16572 851 76360 102 869 103 103 69465 103 21326 128 1997 11680 851 24727 128 47935 1703 41833 128 11014 7805 22438 880 852 103 10781 3810 128 625 103 36183 89585 851 39843 2059 16132 29948 132 10789 103 14584 9734 2790 22202 9942 29217 3234 17432 5848 41887 42566 1022 87129 1468 852 128 25052 6201 852 103 63363 107004 852 132 102\nI1111 11:51:37.323199 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.323450 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.323606 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 1 2 28 32 35 41 42 50 56 60 67 68 70 87 92 102 113 120 122 0\nI1111 11:51:37.323762 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 107004 852 1468 15291 15484 66014 852 33179 4752 26878 16542 852 7021 10629 3060 86503 41833 6201 851 0\nI1111 11:51:37.323925 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.324056 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.324743 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.325013 139695582779200 create_pretraining_data.py:151] tokens: [CLS] керам ##ически [MASK] кирпич . керам ##ически ##и кирпич – это кирпич , котор [MASK] ##и изготавливается из натурального , экологически [MASK] сырья – глины с [MASK] [MASK] [MASK] [MASK] примес ##еи ) . так ##ои [MASK] иногда называют красным из - за его [MASK] оттенка [MASK] [SEP] ##окар ##тон потол [MASK] ##и , Масса ##ино КА , равно ##и [MASK] , 5 миллиметра ##м . дан ##ны ##и тип применяется для устро ##ист [MASK] подвес [MASK] [MASK] ##ков . тип част ##енько заменяется на обыч ##ны ##и стен ##ово ##и , толщ ##ино ##и [MASK] , 5 ( мм ) при устро ##ист ##ве потол ##ков . при использовании для устро ##ист ##ва подвес ##ных потол ##ков листов 12 , 5 ( мм ) [MASK] [SEP]\nI1111 11:51:37.325270 139695582779200 create_pretraining_data.py:161] input_ids: 101 25052 6201 103 53575 132 25052 6201 852 53575 1022 3998 53575 128 2075 103 852 68404 1703 73462 128 63998 103 31130 1022 46836 869 103 103 103 103 49562 15034 122 132 2306 15484 103 12798 14919 37279 1703 130 1758 2752 103 90315 103 102 68600 7831 39361 103 852 128 23563 4007 41079 128 17561 852 103 128 146 52686 866 132 3813 1468 852 7222 22476 2748 13999 1786 103 59060 103 103 2570 132 7222 3087 88193 79776 1469 8607 1468 852 14082 9127 852 128 26559 4007 852 103 128 146 120 9490 122 2790 13999 1786 9078 39361 2570 132 2790 21964 2748 13999 1786 7241 59060 1755 39361 2570 26217 4367 128 146 120 9490 122 103 102\nI1111 11:51:37.325548 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.325796 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.325967 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 3 15 22 27 28 29 30 37 45 47 52 55 57 61 75 77 78 96 126 0\nI1111 11:51:37.326116 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 852 880 42797 28405 9942 89450 120 53575 85624 132 107004 26559 852 154 7241 1755 39361 4367 13855 0\nI1111 11:51:37.326290 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.326442 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\nI1111 11:51:37.327062 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.327316 139695582779200 create_pretraining_data.py:151] tokens: [CLS] толщина первых листов гипс ##окар [MASK] составляла тогда пятнадцать мм . отмет ##им , что листы сак ##кет ##а были [MASK] прарод ##ителями сегодняшних . [SEP] . силикат [MASK] ##и кирпич бывает следующих видов : полно [MASK] ##ы ##и ( монолит ) и пуст ##отел ##ы ##и . силикат ##ны ##и кирпич [MASK] применять для возведения стен и внутренних межк ##вартир ##ных или межк Gore ##атных перегород [MASK] , так как он обладает очень высокими звуко ##изоля ##ционными свои ##ствами . однако , его не целесообразно применять для кладки ц ##окол ##еи , фундамент ##ов , печ ##еи и кам ##инов . очень широк ##ии [MASK] [MASK] [MASK] ##ны [MASK] [MASK] рынке [MASK] прочность и [MASK] [MASK] [MASK] [MASK] позволяют применять ##азмер не только для строительства [SEP]\nI1111 11:51:37.327583 139695582779200 create_pretraining_data.py:161] input_ids: 101 49738 10785 26217 98479 68600 103 15304 9798 49453 9490 132 7292 1568 128 1997 53661 38303 34829 626 3294 103 62617 11274 106509 132 102 132 87129 103 852 53575 28111 19078 11587 156 16542 103 880 852 120 63308 122 851 13627 35582 880 852 132 87129 1468 852 53575 103 31367 2748 45060 14082 851 14263 99165 55065 1755 3474 99165 42548 38120 50191 103 128 2306 2739 2886 19479 7805 36557 61097 57576 36988 8305 17821 132 5656 128 2752 1699 89380 31367 2748 65359 885 13346 15034 128 22493 1388 128 15753 15034 851 6676 6066 132 7805 9178 1524 103 103 103 1468 103 103 15155 103 51486 851 103 103 103 103 23138 31367 88637 1699 4564 2748 13508 102\nI1111 11:51:37.327819 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.328034 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.328176 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 6 21 29 37 53 65 68 106 107 108 110 111 113 114 116 117 118 119 122 0\nI1111 11:51:37.328341 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 17181 4564 1468 24427 39575 23611 1770 70407 128 16332 852 1469 128 51486 81678 87129 1766 41833 2752 0\nI1111 11:51:37.328526 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.328656 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\nI1111 11:51:37.329312 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.329591 139695582779200 create_pretraining_data.py:151] tokens: [CLS] отмет ##им , что листы сак ##кет ##а были только [MASK] [MASK] сегодняшних . [SEP] отцом [MASK] современ ##но [MASK] сух ##ои штукатур ##ки стал тоже американец [MASK] клар ##енс ут ##сман , он и [MASK] промышленное производство гипс ##окар ##тона , предварительно запуст ##ив шум ##ную рекламную кампанию . в результате гипс [MASK] [MASK] очень быстро стал незаменим [MASK] отдел ##очным материалом во всем [MASK] [MASK] ит ##ак , современ ##ны [MASK] лист гипс ##окар ##тона состоит [MASK] зат ##верд ##евшего [MASK] с добав ##ками , и двух [MASK] прочно ##и строительно [MASK] бумаги . \" наш \" лист - это чуть больше 91 % [MASK] ##водного гипса , около 6 % картона и остальное - крахмал , влаг ##а и органическое поверхностно ##е вещество [SEP]\nI1111 11:51:37.329850 139695582779200 create_pretraining_data.py:161] input_ids: 101 7292 1568 128 1997 53661 38303 34829 626 3294 4564 103 103 106509 132 102 20520 103 53104 1438 103 15374 15484 72464 2237 3899 15291 38575 103 70900 7018 5420 78631 128 2886 851 103 54138 13758 98479 68600 17181 128 33206 21104 1581 24034 3065 75428 26157 132 845 6542 98479 103 103 7805 13586 3899 89820 103 6867 20422 39166 2743 10556 103 103 10262 1533 128 53104 1468 103 14327 98479 68600 17181 11806 103 5239 9384 44407 103 869 9791 6887 128 851 5547 103 48916 852 80410 103 24305 132 108 10189 108 14327 130 3998 18836 8980 13031 114 103 105572 107061 128 4929 148 114 104541 851 43757 130 118803 128 37559 626 851 99640 111309 842 31856 102\nI1111 11:51:37.330093 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.330425 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.330658 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 11 12 17 20 28 36 54 55 60 66 67 73 79 83 90 94 107 113 125 0\nI1111 11:51:37.330829 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 62617 11274 108 852 128 97425 68600 7831 2800 10826 132 852 1703 107061 45208 852 36096 114 842 0\nI1111 11:51:37.331007 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.331136 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.331775 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.332052 139695582779200 create_pretraining_data.py:151] tokens: [CLS] кирпич – это кирпич , котор ##ы ##и изготавливается из натурального , экологически чистого сырья – [MASK] с применением различных добавок ( примес ##еи ) . так ##ои кирпич иногда называют красным из - за [MASK] характерного оттенка . так [MASK] цвет получается [MASK] результате обжиг ##а . керам ##ически ##и кирпич изготавливают [MASK] методу пласт ##ического форм [MASK] либо полус ##ухо Википед пресс ##ования . чаще всего [MASK] производства красного кирпича используют [MASK] ##ы [SEP] отмет [MASK] , что листы сак ##кет ##а [MASK] только прарод ##ителями сегодняшних . \" отцом \" современ [MASK] ##и сух ##ои штукатур ##ки стал тоже [MASK] , клар ##енс ут ##сман , [MASK] и наладил [MASK] производство гипс ##окар ##тона , Осад запуст ##ив шум ##ную рекламную кампанию . [SEP]\nI1111 11:51:37.332302 139695582779200 create_pretraining_data.py:161] input_ids: 101 53575 1022 3998 53575 128 2075 880 852 68404 1703 73462 128 63998 42797 31130 1022 103 869 28405 9942 89450 120 49562 15034 122 132 2306 15484 53575 12798 14919 37279 1703 130 1758 103 85624 90315 132 2306 103 9542 34583 103 6542 72666 626 132 25052 6201 852 53575 84337 103 61809 13130 4737 5093 103 8568 33916 65525 40612 8609 3803 132 16462 6675 103 11644 26494 41833 17432 103 880 102 7292 103 128 1997 53661 38303 34829 626 103 4564 62617 11274 106509 132 108 20520 108 53104 103 852 15374 15484 72464 2237 3899 15291 103 128 70900 7018 5420 78631 128 103 851 97425 103 13758 98479 68600 17181 128 75284 21104 1581 24034 3065 75428 26157 132 102\nI1111 11:51:37.332544 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.332745 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.332906 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 8 17 36 39 41 44 54 59 63 69 74 78 80 85 95 103 110 113 119 0\nI1111 11:51:37.333209 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 852 46836 2752 132 15484 845 1516 3803 1471 2748 3240 1568 1997 3294 1438 38575 2886 54138 33206 0\nI1111 11:51:37.333451 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.333606 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\nI1111 11:51:37.334245 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.334523 139695582779200 create_pretraining_data.py:151] tokens: [CLS] практ ##ичны ##и , проч [MASK] ##и , долгов ##еч ##ны ##и и в тоже время [MASK] ##ои строитель ##ны ##и [MASK] с отличным ##и [MASK] ##ционными характеристиками и многовек ##ово ##и истори [MASK] , котор [MASK] ##и [MASK] чаще используют в современном [MASK] здании и сооружении . кирпич изготавливают из натурального , экологически чистого сырья . с [MASK] ##и уверенностью можно [MASK] , что здания и сооружения , [MASK] из кирпича , [MASK] очень красив [SEP] обыч ##ны [MASK] длился стен ##ово ##и - [MASK] распространен ##ны ##и и востребован ##ны ##и рынком тип гипс ##окар ##тон ##ных листов , толщина листа составляет 12 - 12 [MASK] 5 [MASK] , габариты листа 2500 [MASK] ##120 ##0 и 3000 ##х ##120 ##0 ( мм ) . [SEP]\nI1111 11:51:37.334789 139695582779200 create_pretraining_data.py:161] input_ids: 101 8251 33241 852 128 11560 103 852 128 23802 2311 1468 852 851 845 15291 3299 103 15484 7478 1468 852 103 869 66014 852 103 36988 50082 851 81972 9127 852 33179 103 128 2075 103 852 103 16462 17432 845 26878 103 16572 851 76360 132 53575 84337 1703 73462 128 63998 42797 31130 132 869 103 852 69465 7021 103 128 1997 11680 851 24727 128 103 1703 41833 128 103 7805 22438 102 8607 1468 103 53372 14082 9127 852 130 103 67708 1468 852 851 113256 1468 852 64084 7222 98479 68600 7831 1755 26217 128 49738 36507 6637 4367 130 4367 103 146 103 128 88030 36507 25346 103 116827 137 851 15847 884 116827 137 120 9490 122 132 102\nI1111 11:51:37.335019 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.335215 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.335390 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 6 17 22 26 34 37 39 44 59 63 68 70 74 80 81 86 108 110 115 0\nI1111 11:51:37.335541 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 1468 73239 15772 18981 15034 880 4752 19789 16542 21326 24727 47935 11014 852 128 9737 128 27932 884 0\nI1111 11:51:37.335686 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.335825 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\nI1111 11:51:37.336453 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.336694 139695582779200 create_pretraining_data.py:151] tokens: [CLS] таким [MASK] , облицов геймплея ##и кирпич служит для защиты и украшения различных здании и сооружении . это сам ##ы ##и дорого ##и вид кирпича . [SEP] либо фасад ##ным . характерными особенностями внуком ##очного кирпича являются высокая прочность , мороз [MASK] ##икос ##ть [MASK] цвет ##осто ##икос ##ть , низкое влаго ##по ##гл ##ощ ##ение . на сегодняш ##нии день существует огромное количество разновид [MASK] ##еи облицов ##очного кирпича [MASK] современ [MASK] ##и облицов ##очны ##и кирпич характеризуется большим разнообразием форм , факту ein , цветов и оттенков . он производится в виде стандартных прямоугольник [MASK] , а также [MASK] ##идно ##и , закруг ##ленно [MASK] [MASK] трапеци ##евид ##но ##и , [MASK] ##исто ##и [MASK] вит ##ои , со скош ##енными углами , фигур [SEP]\nI1111 11:51:37.336931 139695582779200 create_pretraining_data.py:161] input_ids: 101 11510 103 128 63363 90595 852 53575 22618 2748 14117 851 35338 9942 16572 851 76360 132 3998 3248 880 852 22062 852 3810 41833 132 102 8568 29630 2010 132 66447 43732 56312 12511 41833 8729 26352 51486 128 45924 103 55627 4099 103 9542 6915 55627 4099 128 61291 107600 23784 5355 4542 2011 132 1469 18071 10781 6622 13933 28126 9595 22328 103 15034 63363 12511 41833 103 53104 103 852 63363 107004 852 53575 28197 15906 63077 5093 128 20615 10802 128 25258 851 60436 132 2886 24050 845 7310 43713 109078 103 128 625 3060 103 49196 852 128 48712 17067 103 103 98869 10329 1438 852 128 103 34792 852 103 22556 15484 128 1580 99992 10864 68679 128 13766 102\nI1111 11:51:37.337133 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.337348 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.337525 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 2 5 34 42 45 49 58 66 71 73 85 97 101 106 107 108 114 117 123 0\nI1111 11:51:37.337672 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 7363 107004 63363 6915 851 4099 1469 2008 132 1468 874 1388 72954 17067 852 128 18351 128 10864 0\nI1111 11:51:37.337804 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.337936 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.338516 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.338752 139695582779200 create_pretraining_data.py:151] tokens: [CLS] но мы кос ##нем ##ся только общих моментов [MASK] [SEP] ##окар ##тона является обшивка [MASK] каркас ##ов [MASK] помощи самор ##езов . [MASK] качестве несущих конструкции для [MASK] применяются каркас ##ы , собранные из брус ##ов или же , что гораздо чаще , из заводского изготовления профил ##еи из алюминиевых сплавов . существует несколько разновид ##DO ##еи профил ##еи [MASK] гипс ##окар ##тона , кроме того , кажд ##ы ##и тип профиля имеет ряд тип ##оразмер ##ов . комплекта ##ция профил [MASK] включает в себя также набор различных [MASK] ##лении , [MASK] ##ов , соедин ##ителе ##и для наращивания профил [MASK] [MASK] прочих дет [MASK] ##и . кроме крепления к каркаса ##м посредством винтов - самор ##езов листы гипс ##окар ##тона могут быть [MASK] же прикле [SEP]\nI1111 11:51:37.338968 139695582779200 create_pretraining_data.py:161] input_ids: 101 3435 8235 9098 5777 1523 4564 27676 43296 103 102 68600 17181 4415 114950 103 57909 1388 103 11007 76931 51752 132 103 6620 76034 19253 2748 103 29025 57909 880 128 41717 1703 54261 1388 3474 3629 128 1997 19120 16462 128 1703 62914 26334 27517 15034 1703 85615 50463 132 13933 5325 22328 81956 15034 27517 15034 103 98479 68600 17181 128 12025 4105 128 6938 880 852 7222 44921 7497 6841 7222 97951 1388 132 44336 3364 27517 103 14247 845 6678 3060 16734 9942 103 7425 128 103 1388 128 9948 43152 852 2748 110013 27517 103 103 22071 5251 103 852 132 12025 48442 861 101849 866 22155 21519 130 76931 51752 53661 98479 68600 17181 7603 6345 103 3629 96876 102\nI1111 11:51:37.339170 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.339359 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.339525 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 4 9 15 18 23 28 56 60 80 81 82 84 89 92 101 102 104 105 124 0\nI1111 11:51:37.339676 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 5777 132 101535 2790 845 84263 2008 2748 3364 27517 15034 845 10996 59060 15034 851 5251 5386 2306 0\nI1111 11:51:37.339832 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.339972 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.340542 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.340779 139695582779200 create_pretraining_data.py:151] tokens: [CLS] благодаря многообраз [MASK] [MASK] [MASK] гам ##мы и неповтор ##имо ##и факту ##ре силикат ##ны ##и кирпич [MASK] ##ит фасад любого здания либо сооружения . [SEP] ##ически ##и кирпич . керам ##ически [MASK] кирпич – шрифта кирпич , [MASK] ##ы ##и изготавливается из натурального , экологически чистого сырья – глины с применением различных добавок ( примес [MASK] ) . так [MASK] кирпич иногда называют красным из - за его характерного оттенка Лютер [MASK] ##ои [MASK] получается в результате обжиг ##а . керам ##ически ##и кирпич изготавливают по [MASK] пласт ##ического форм ##ования либо [MASK] ##ухо ##го пресс ##ования . чаще всего [MASK] производства красного кирпича используют [MASK] ##ы ##и метод [MASK] [MASK] соответствие со стандартами , керам ##ически ##и кирпич может быть следующих размеров : один [SEP]\nI1111 11:51:37.341003 139695582779200 create_pretraining_data.py:161] input_ids: 101 11179 37913 103 103 103 28451 5640 851 64057 7065 852 20615 2076 87129 1468 852 53575 103 1502 29630 24508 11680 8568 24727 132 102 6201 852 53575 132 25052 6201 103 53575 1022 98885 53575 128 103 880 852 68404 1703 73462 128 63998 42797 31130 1022 46836 869 28405 9942 89450 120 49562 103 122 132 2306 103 53575 12798 14919 37279 1703 130 1758 2752 85624 90315 63262 103 15484 103 34583 845 6542 72666 626 132 25052 6201 852 53575 84337 1516 103 13130 4737 5093 3803 8568 103 65525 1471 8609 3803 132 16462 6675 103 11644 26494 41833 17432 103 880 852 11030 103 103 35489 1580 69485 128 25052 6201 852 53575 5269 6345 19078 25463 156 5259 102\nI1111 11:51:37.341198 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.341401 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.341551 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 1 3 4 5 18 33 36 39 57 61 72 73 75 88 94 102 107 111 112 0\nI1111 11:51:37.341685 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 11179 3080 25258 15484 60495 852 3998 2075 15034 15484 132 2306 9542 61809 33916 2748 3240 132 845 0\nI1111 11:51:37.341822 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.341961 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.342524 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.342747 139695582779200 create_pretraining_data.py:151] tokens: [CLS] [MASK] ##ои ##ки ##и гипс ##окар ##тон ( г ##кл ##о ) в основном [MASK] для устро ##ист ##ва алтай ##ов [MASK] облицов ##ки поверхност ##еи стен и потол [MASK] с большим сосредоточен ##ием инженерных [MASK] ##и , с повышенным ##и [MASK] по огнест ##ои ##кости конструкции , таких как лест ##ничные клетки здании . [SEP] о технологии монтажа . детально вы сможет ##е ознакомиться с нею [MASK] инструкция ##х по монтаж ##у , разработанных [MASK] производителем , представленным на рынке строительных материалов . в кажд [MASK] из них вы сможет ##е на ##ити деталь ##ные трёхгран [MASK] устро ##ист ##ву практически всех типов конструкции , возможных к исполнению с [MASK] материала [MASK] [MASK] также норм ##орас [MASK] материалов на 1 кв . метр поверхност ##еи [SEP]\nI1111 11:51:37.343000 139695582779200 create_pretraining_data.py:161] input_ids: 101 103 15484 2237 852 98479 68600 7831 120 847 50770 613 122 845 10171 103 2748 13999 1786 7241 61640 1388 103 63363 2237 33195 15034 14082 851 39361 103 869 15906 94410 4066 40241 103 852 128 869 69508 852 103 1516 26802 15484 18130 19253 128 9884 2739 23295 67260 22595 16572 132 102 612 16842 61930 132 55272 1761 17530 842 43485 869 64465 103 97398 884 1516 31427 876 128 58462 103 40168 128 101448 1469 15155 29217 16135 132 845 6938 103 1703 5768 1761 17530 842 1469 13305 64642 2059 108823 103 13999 1786 18459 11774 6399 21150 19253 128 22431 861 44047 869 103 20531 103 103 3060 11082 95898 103 16135 1469 138 6603 132 26168 33195 15034 102\nI1111 11:51:37.343189 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.343397 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.343552 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 1 11 15 20 22 30 36 42 52 68 76 80 87 97 98 111 113 114 118 0\nI1111 11:51:37.343684 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 26802 613 22476 21459 128 2570 69758 39797 67260 845 34217 1469 15484 30129 1516 28405 128 625 50734 0\nI1111 11:51:37.343826 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.343962 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 0\nI1111 11:51:37.344568 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.344781 139695582779200 create_pretraining_data.py:151] tokens: [CLS] силикат ##ны ##и [MASK] экологи ##чен и обладает ##альностью высоко ##и звуко ##изоля [MASK] ##еи , что позволяет применять его для строительства самых разных архитектурных строении . силикат ##ны [MASK] [MASK] – это [MASK] эконом ##ичны ##и и неприхот ##ливы ##и строитель ##ны [MASK] материал . [SEP] особую популярность у строит ##еле ##и гипс ##окар ##тон получил за удобство при [MASK] , возможность сокращения объемов \" мокр ##ых \" процессов при отделке помещении , за [MASK] времени производства работ , Трени технолог ##ичность материала . [MASK] ##ся он и заказчикам . [SEP]\nI1111 11:51:37.345023 139695582779200 create_pretraining_data.py:161] input_ids: 101 87129 1468 852 103 44593 17092 851 19479 39485 20658 852 61097 57576 103 15034 128 1997 13289 31367 2752 2748 13508 10586 12246 44341 66553 132 87129 1468 103 103 1022 3998 103 6354 33241 852 851 102777 101227 852 7478 1468 103 15772 132 102 38712 20829 875 50967 8151 852 98479 68600 7831 6149 1758 103866 2790 103 128 10796 29622 51107 108 71308 2558 108 21641 2790 89660 26485 128 1758 103 6651 11644 3234 128 106694 9980 23933 20531 132 103 1523 2886 851 95117 132 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.345233 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.345447 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\nI1111 11:51:37.345590 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 4 9 14 18 30 31 34 37 44 61 69 76 81 86 0 0 0 0 0 0\nI1111 11:51:37.345818 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 53575 7805 1827 13289 852 53575 12923 852 852 21964 108 23391 1758 96859 0 0 0 0 0 0\nI1111 11:51:37.346075 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\nI1111 11:51:37.346246 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\nI1111 11:51:37.346895 139695582779200 create_pretraining_data.py:149] *** Example ***\nI1111 11:51:37.347148 139695582779200 create_pretraining_data.py:151] tokens: [CLS] силикат [MASK] [MASK] [MASK] бывает следующих видов [MASK] полно ##тел ##ы ##и ( монолит ) и пуст ##отел ##ы ##и . силикат ##ны ##и [MASK] рекомендуется 忍 для [MASK] стен и внутренних межк ##вартир ##ных или [MASK] [MASK] ##атных перегород [MASK] , так [MASK] он обладает очень высокими звуко ##изоля [MASK] свои ##ствами . [SEP] [MASK] еще [MASK] ##и модифика ##ци [MASK] обычного листа является так называем ##ы ##и ар ##очны ##и гипс ##окар ##тон , толщина листа которого равна 6 , 5 миллиметра ##м . [MASK] ##ны ##и тип листов [MASK] для устро ##ист ##ва ради ##альных , волнообраз ##ных , купол ##ообразных форм из - [MASK] свое ##и замечательно ##и гибкости . люб ##ои замысел архитектора в части устро ##ист ##ва потол ##ков может [SEP]\nI1111 11:51:37.347426 139695582779200 create_pretraining_data.py:161] input_ids: 101 87129 103 103 103 28111 19078 11587 103 16542 24427 880 852 120 63308 122 851 13627 35582 880 852 132 87129 1468 852 103 39575 4290 2748 103 14082 851 14263 99165 55065 1755 3474 103 103 38120 50191 103 128 2306 103 2886 19479 7805 36557 61097 57576 103 8305 17821 132 102 103 8106 103 852 23565 1827 103 34799 36507 4415 2306 11698 880 852 3132 107004 852 98479 68600 7831 128 49738 36507 6213 26578 148 128 146 52686 866 132 103 1468 852 7222 26217 103 2748 13999 1786 7241 7809 5532 128 108659 1755 128 41251 42562 5093 1703 130 103 6277 852 107268 852 119025 132 6556 15484 55883 22895 845 5931 13999 1786 7241 39361 2570 5269 102\nI1111 11:51:37.347659 139695582779200 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.347889 139695582779200 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\nI1111 11:51:37.348051 139695582779200 create_pretraining_data.py:161] masked_lm_positions: 2 3 4 8 25 27 29 37 38 41 44 50 51 56 58 62 87 92 108 0\nI1111 11:51:37.348193 139695582779200 create_pretraining_data.py:161] masked_lm_ids: 1468 852 53575 156 53575 31367 45060 99165 23611 1770 2739 57576 36988 132 7635 15034 3813 12404 1758 0\nI1111 11:51:37.348353 139695582779200 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\nI1111 11:51:37.348500 139695582779200 create_pretraining_data.py:161] next_sentence_labels: 1\n","name":"stdout"},{"output_type":"stream","text":"I1111 11:51:37.377014 139695582779200 create_pretraining_data.py:166] Wrote 110 total instances\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nAUTO = tf.data.experimental.AUTOTUNE","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python run_pretraining.py \\\n  --input_file=/kaggle/working/tf_examples.tfrecord \\\n  --output_dir=/kaggle/working/pretraining_output \\\n  --do_train=True \\\n  --do_eval=True \\\n  --bert_config_file=/kaggle/input/sentence-ru-cased-l12-h768-a12/bert_config.json \\\n  --init_checkpoint=/kaggle/input/sentence-ru-cased-l12-h768-a12/bert_model.ckpt \\\n  --train_batch_size=32 \\\n  --max_seq_length=128 \\\n  --max_predictions_per_seq=20 \\\n  --num_train_steps=1 \\\n  --num_warmup_steps=10 \\\n  --learning_rate=2e-5","execution_count":10,"outputs":[{"output_type":"stream","text":"W1111 11:51:48.958547 140120507623232 module_wrapper.py:139] From run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n\nW1111 11:51:48.958783 140120507623232 module_wrapper.py:139] From run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n\nW1111 11:51:48.959130 140120507623232 module_wrapper.py:139] From /kaggle/input/bertsrc/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nW1111 11:51:48.967796 140120507623232 module_wrapper.py:139] From run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n\nW1111 11:51:48.968508 140120507623232 module_wrapper.py:139] From run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n\nW1111 11:51:48.969546 140120507623232 module_wrapper.py:139] From run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n\nI1111 11:51:48.969729 140120507623232 run_pretraining.py:420] *** Input Files ***\nI1111 11:51:48.969875 140120507623232 run_pretraining.py:422]   /kaggle/working/tf_examples.tfrecord\nW1111 11:51:48.970080 140120507623232 lazy_loader.py:50] \nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nI1111 11:51:49.859652 140120507623232 utils.py:141] NumExpr defaulting to 4 threads.\nW1111 11:51:50.536052 140120507623232 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6fe493bb00>) includes params argument, but params are not passed to Estimator.\nI1111 11:51:50.537276 140120507623232 estimator.py:212] Using config: {'_model_dir': '/kaggle/working/pretraining_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6fe4952fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\nI1111 11:51:50.537754 140120507623232 tpu_context.py:220] _TPUContext: eval_on_tpu True\nW1111 11:51:50.538031 140120507623232 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\nI1111 11:51:50.538187 140120507623232 run_pretraining.py:459] ***** Running training *****\nI1111 11:51:50.538319 140120507623232 run_pretraining.py:460]   Batch size = 32\nW1111 11:51:50.544764 140120507623232 deprecation.py:506] From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nW1111 11:51:50.545416 140120507623232 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\nW1111 11:51:50.555695 140120507623232 module_wrapper.py:139] From run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n\nW1111 11:51:50.561949 140120507623232 deprecation.py:323] From run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.experimental.parallel_interleave(...)`.\nW1111 11:51:50.562213 140120507623232 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\nW1111 11:51:50.589884 140120507623232 deprecation.py:323] From run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.experimental.map_and_batch(...)`.\nW1111 11:51:50.590162 140120507623232 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\nW1111 11:51:50.691314 140120507623232 module_wrapper.py:139] From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n\nW1111 11:51:50.862050 140120507623232 deprecation.py:323] From run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI1111 11:51:50.886256 140120507623232 estimator.py:1148] Calling model_fn.\nI1111 11:51:50.886623 140120507623232 tpu_estimator.py:3124] Running train on CPU\nI1111 11:51:50.887154 140120507623232 run_pretraining.py:117] *** Features ***\nI1111 11:51:50.887415 140120507623232 run_pretraining.py:119]   name = input_ids, shape = (32, 128)\nI1111 11:51:50.887591 140120507623232 run_pretraining.py:119]   name = input_mask, shape = (32, 128)\nI1111 11:51:50.887760 140120507623232 run_pretraining.py:119]   name = masked_lm_ids, shape = (32, 20)\nI1111 11:51:50.887924 140120507623232 run_pretraining.py:119]   name = masked_lm_positions, shape = (32, 20)\nI1111 11:51:50.888075 140120507623232 run_pretraining.py:119]   name = masked_lm_weights, shape = (32, 20)\nI1111 11:51:50.888269 140120507623232 run_pretraining.py:119]   name = next_sentence_labels, shape = (32, 1)\nI1111 11:51:50.888442 140120507623232 run_pretraining.py:119]   name = segment_ids, shape = (32, 128)\nW1111 11:51:50.888836 140120507623232 module_wrapper.py:139] From /kaggle/input/bertsrc/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n\nW1111 11:51:50.890796 140120507623232 module_wrapper.py:139] From /kaggle/input/bertsrc/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n\nW1111 11:51:50.916200 140120507623232 module_wrapper.py:139] From /kaggle/input/bertsrc/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n\n","name":"stdout"},{"output_type":"stream","text":"W1111 11:51:50.952824 140120507623232 deprecation.py:506] From /kaggle/input/bertsrc/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nW1111 11:51:50.968776 140120507623232 deprecation.py:323] From /kaggle/input/bertsrc/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.Dense instead.\nW1111 11:51:50.970072 140120507623232 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `layer.__call__` method instead.\nW1111 11:51:53.394193 140120507623232 module_wrapper.py:139] From run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n\nW1111 11:51:53.411009 140120507623232 module_wrapper.py:139] From run_pretraining.py:165: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n\nI1111 11:51:54.076269 140120507623232 run_pretraining.py:167] **** Trainable Variables ****\nI1111 11:51:54.076591 140120507623232 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (119547, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.076817 140120507623232 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.076985 140120507623232 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.077135 140120507623232 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.077299 140120507623232 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.077462 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.077613 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.077766 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.077906 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.078038 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.078196 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.078355 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.078531 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.078681 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.078804 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.078944 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.079089 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.079213 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.079388 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.079559 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.079684 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.079835 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.079980 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.080117 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.080273 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.080420 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.080576 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.080718 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.080855 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.080998 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.081126 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.081289 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.081479 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.081629 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.081761 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.081906 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.082040 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.082189 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.082339 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.082495 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.082652 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.082776 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.082924 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.083060 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.083199 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.083358 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.083508 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.083661 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.083821 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.083949 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.084088 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.084232 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.084397 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.084549 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.084705 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.084829 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.085002 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.085153 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.085290 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.085449 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.085611 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.085736 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.085875 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.086011 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.086139 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.086290 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.086451 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.086585 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.086728 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.086846 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.086997 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.087128 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.087271 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.087436 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.087581 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.087727 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.087887 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.088008 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.088146 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.088289 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.088448 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.088592 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.088736 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.088859 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.089005 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.089129 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.089274 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.089436 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.089588 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.089728 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.089884 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.090007 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.090148 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.090299 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.090445 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.090588 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.090735 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.090857 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.091012 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.091145 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.091280 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.091445 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.091586 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.091730 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.091885 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.092009 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.092152 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.092299 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.092455 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.092591 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.092730 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.092849 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.093000 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.093129 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.093271 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.093439 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.093570 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.093702 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.093853 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.093973 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.094123 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.094263 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.094424 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.094573 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.094711 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.094853 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.094992 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.095116 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.095278 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.095434 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.095597 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.095745 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.095865 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.096005 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.096145 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.096285 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.096462 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.096586 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.096734 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.096876 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.097014 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.097166 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.097298 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.097459 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.097612 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.097998 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.098230 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.098461 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.098649 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.098825 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.099020 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.099203 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.099392 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.099550 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.099723 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.099891 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.100043 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.100198 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.100401 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.100788 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.100976 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.101145 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.101294 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.101480 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.101655 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.101804 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.101966 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.102101 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.102270 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.102446 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.102692 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.102940 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.103114 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.103433 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.103655 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.103837 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.104014 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.104161 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.104359 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.104539 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.104686 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.104812 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.104999 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.105146 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.105283 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.105492 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.105673 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.105824 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.105976 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.106125 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.106276 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.106439 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:51:54.106599 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:51:54.106761 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.106898 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.107039 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.107184 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.107316 140120507623232 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:51:54.107493 140120507623232 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:51:54.107698 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\nI1111 11:51:54.107912 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\nI1111 11:51:54.108091 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\nI1111 11:51:54.108253 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\nI1111 11:51:54.108474 140120507623232 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (119547,)\nI1111 11:51:54.108654 140120507623232 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\nI1111 11:51:54.108837 140120507623232 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\nW1111 11:51:54.109104 140120507623232 module_wrapper.py:139] From /kaggle/input/bertsrc/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n\nW1111 11:51:54.110392 140120507623232 module_wrapper.py:139] From /kaggle/input/bertsrc/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n\n","name":"stdout"},{"output_type":"stream","text":"W1111 11:51:54.324723 140120507623232 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nI1111 11:52:01.610058 140120507623232 estimator.py:1150] Done calling model_fn.\nI1111 11:52:01.612006 140120507623232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\nI1111 11:52:05.207699 140120507623232 monitored_session.py:240] Graph was finalized.\n2020-11-11 11:52:05.208245: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2020-11-11 11:52:05.216056: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz\n2020-11-11 11:52:05.216361: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556e7ecb8b30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-11-11 11:52:05.216429: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2020-11-11 11:52:05.218538: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2020-11-11 11:52:05.218579: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n2020-11-11 11:52:05.218611: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2d0183c941bb): /proc/driver/nvidia/version does not exist\nI1111 11:52:15.762012 140120507623232 session_manager.py:500] Running local_init_op.\nI1111 11:52:16.084729 140120507623232 session_manager.py:502] Done running local_init_op.\nI1111 11:52:25.922588 140120507623232 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /kaggle/working/pretraining_output/model.ckpt.\nI1111 11:53:30.952587 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.033919\nI1111 11:53:30.956932 140120507623232 tpu_estimator.py:2308] examples/sec: 1.08541\nI1111 11:53:52.878769 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0456075\nI1111 11:53:52.879282 140120507623232 tpu_estimator.py:2308] examples/sec: 1.45944\nI1111 11:54:14.482288 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0462887\nI1111 11:54:14.484194 140120507623232 tpu_estimator.py:2308] examples/sec: 1.48124\nI1111 11:54:37.493837 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0434565\nI1111 11:54:37.494421 140120507623232 tpu_estimator.py:2308] examples/sec: 1.39061\nI1111 11:54:59.237091 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0459912\nI1111 11:54:59.237596 140120507623232 tpu_estimator.py:2308] examples/sec: 1.47172\nI1111 11:55:21.907116 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0441113\nI1111 11:55:21.907759 140120507623232 tpu_estimator.py:2308] examples/sec: 1.41156\nI1111 11:55:43.669082 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0459516\nI1111 11:55:43.669611 140120507623232 tpu_estimator.py:2308] examples/sec: 1.47045\nI1111 11:56:05.602175 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0455931\nI1111 11:56:05.602660 140120507623232 tpu_estimator.py:2308] examples/sec: 1.45898\nI1111 11:56:28.471665 140120507623232 tpu_estimator.py:2307] global_step/sec: 0.0437265\nI1111 11:56:28.472337 140120507623232 tpu_estimator.py:2308] examples/sec: 1.39925\nI1111 11:56:28.473007 140120507623232 basic_session_run_hooks.py:606] Saving checkpoints for 10 into /kaggle/working/pretraining_output/model.ckpt.\nI1111 11:56:32.612440 140120507623232 estimator.py:371] Loss for final step: 9.055443.\nI1111 11:56:32.613038 140120507623232 error_handling.py:101] training_loop marked as finished\nI1111 11:56:32.614220 140120507623232 run_pretraining.py:469] ***** Running evaluation *****\nI1111 11:56:32.614356 140120507623232 run_pretraining.py:470]   Batch size = 8\nI1111 11:56:32.659587 140120507623232 estimator.py:1148] Calling model_fn.\nI1111 11:56:32.659925 140120507623232 tpu_estimator.py:3124] Running eval on CPU\nI1111 11:56:32.660517 140120507623232 run_pretraining.py:117] *** Features ***\nI1111 11:56:32.660748 140120507623232 run_pretraining.py:119]   name = input_ids, shape = (8, 128)\nI1111 11:56:32.660906 140120507623232 run_pretraining.py:119]   name = input_mask, shape = (8, 128)\nI1111 11:56:32.661050 140120507623232 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 20)\nI1111 11:56:32.661188 140120507623232 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 20)\nI1111 11:56:32.661326 140120507623232 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 20)\nI1111 11:56:32.661493 140120507623232 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\nI1111 11:56:32.661631 140120507623232 run_pretraining.py:119]   name = segment_ids, shape = (8, 128)\nI1111 11:56:35.339792 140120507623232 run_pretraining.py:167] **** Trainable Variables ****\nI1111 11:56:35.340082 140120507623232 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (119547, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.340292 140120507623232 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.340487 140120507623232 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.340644 140120507623232 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.340816 140120507623232 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.340953 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.341102 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.341262 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.341433 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.341571 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.341754 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.341895 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.342036 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.342188 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.342312 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.342473 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.342636 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.342770 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.342923 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.343063 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.343184 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.343339 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.343502 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.343636 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.343797 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.343922 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.344064 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.344206 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.344335 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.344506 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.344642 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.344779 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.344956 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.345094 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.345233 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.345393 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.345522 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.345657 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.345831 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.345954 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.346104 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.346239 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.346396 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.346551 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.346685 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.346827 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.346959 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.347059 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.347158 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.347250 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.347408 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.347558 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.347694 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.347835 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.347973 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.348102 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.348239 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.348390 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.348539 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.348672 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.348815 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.348917 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.349027 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.349128 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.349233 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.349331 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.349465 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.349564 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.349662 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.349765 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.349871 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.349969 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.350074 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.350172 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.350275 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.350385 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.350494 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.350592 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.350695 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.350800 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.350905 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.351004 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.351108 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.351206 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.351302 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.351428 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.351547 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.351649 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.351757 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.351857 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.351961 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.352059 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.352162 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.352264 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.352386 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.352491 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.352596 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.352694 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.352805 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.352905 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.353002 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.353101 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.353205 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.353303 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.353420 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.353522 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.353625 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.353724 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.353833 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.353930 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.354035 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.354132 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.354271 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.354384 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.354518 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.354619 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.354717 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.354823 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.354927 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.355025 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.355128 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.355232 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.355345 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.355486 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.355594 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.355693 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.355797 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.355895 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.355998 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.356096 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.356199 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.356298 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.356411 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.356514 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.356618 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.356716 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.356826 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.356924 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.357030 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.357157 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.357304 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.357426 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.357528 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.357628 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.357738 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.357840 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.357944 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.358043 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.358142 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.358242 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.358355 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.358470 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.358574 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.358671 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.358780 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.358879 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.358982 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.359098 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.359196 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.359293 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.359409 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","name":"stdout"},{"output_type":"stream","text":"I1111 11:56:35.359511 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.359616 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.359714 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.359821 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.359974 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.360138 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.360285 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.360460 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.360599 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.360747 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.360878 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.361015 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.361144 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.361275 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.361449 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.361626 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.361780 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.361968 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.362139 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.362314 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.362517 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.362706 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.362910 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.363069 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.363211 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.363392 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.363559 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.363709 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.363868 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.363991 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.364140 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\nI1111 11:56:35.364308 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\nI1111 11:56:35.364480 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.364634 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.364788 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.364916 140120507623232 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.365083 140120507623232 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\nI1111 11:56:35.365236 140120507623232 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\nI1111 11:56:35.365448 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\nI1111 11:56:35.365630 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\nI1111 11:56:35.365807 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\nI1111 11:56:35.365983 140120507623232 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\nI1111 11:56:35.366151 140120507623232 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (119547,)\nI1111 11:56:35.366307 140120507623232 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\nI1111 11:56:35.366495 140120507623232 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\nW1111 11:56:35.373273 140120507623232 module_wrapper.py:139] From run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n\nW1111 11:56:35.390009 140120507623232 module_wrapper.py:139] From run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n\nI1111 11:56:35.439004 140120507623232 estimator.py:1150] Done calling model_fn.\nI1111 11:56:35.459790 140120507623232 evaluation.py:255] Starting evaluation at 2020-11-11T11:56:35Z\nI1111 11:56:36.430500 140120507623232 monitored_session.py:240] Graph was finalized.\nI1111 11:56:36.432192 140120507623232 saver.py:1284] Restoring parameters from /kaggle/working/pretraining_output/model.ckpt-10\nI1111 11:56:37.420942 140120507623232 session_manager.py:500] Running local_init_op.\nI1111 11:56:37.511881 140120507623232 session_manager.py:502] Done running local_init_op.\nI1111 11:56:56.896613 140120507623232 evaluation.py:167] Evaluation [10/100]\nI1111 11:57:12.966227 140120507623232 evaluation.py:167] Evaluation [20/100]\nI1111 11:57:29.396245 140120507623232 evaluation.py:167] Evaluation [30/100]\nI1111 11:57:45.513518 140120507623232 evaluation.py:167] Evaluation [40/100]\nI1111 11:58:01.157962 140120507623232 evaluation.py:167] Evaluation [50/100]\nI1111 11:58:17.451227 140120507623232 evaluation.py:167] Evaluation [60/100]\nI1111 11:58:34.006895 140120507623232 evaluation.py:167] Evaluation [70/100]\n","name":"stdout"},{"output_type":"stream","text":"I1111 11:58:50.159387 140120507623232 evaluation.py:167] Evaluation [80/100]\nI1111 11:59:05.803962 140120507623232 evaluation.py:167] Evaluation [90/100]\nI1111 11:59:22.602163 140120507623232 evaluation.py:167] Evaluation [100/100]\nI1111 11:59:22.765046 140120507623232 evaluation.py:275] Finished evaluation at 2020-11-11-11:59:22\nI1111 11:59:22.765399 140120507623232 estimator.py:2049] Saving dict for global step 10: global_step = 10, loss = 9.023505, masked_lm_accuracy = 0.051591065, masked_lm_loss = 8.419887, next_sentence_accuracy = 0.88625, next_sentence_loss = 0.6000477\nI1111 11:59:23.313268 140120507623232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10: /kaggle/working/pretraining_output/model.ckpt-10\nI1111 11:59:23.314178 140120507623232 error_handling.py:101] evaluation_loop marked as finished\nI1111 11:59:23.314461 140120507623232 run_pretraining.py:483] ***** Eval results *****\nI1111 11:59:23.314592 140120507623232 run_pretraining.py:485]   global_step = 10\nI1111 11:59:23.314780 140120507623232 run_pretraining.py:485]   loss = 9.023505\nI1111 11:59:23.314892 140120507623232 run_pretraining.py:485]   masked_lm_accuracy = 0.051591065\nI1111 11:59:23.314990 140120507623232 run_pretraining.py:485]   masked_lm_loss = 8.419887\nI1111 11:59:23.315080 140120507623232 run_pretraining.py:485]   next_sentence_accuracy = 0.88625\nI1111 11:59:23.315168 140120507623232 run_pretraining.py:485]   next_sentence_loss = 0.6000477\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}