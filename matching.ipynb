{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorboard==2.2.0 --use-feature=2020-resolver\n!pip install tensorflow_text>=2.0.0rc0 --use-feature=2020-resolver\n!pip install -U sentence-transformers --use-feature=2020-resolver\n!pip install razdel\n!pip install navec\n!pip install slovnet","execution_count":6,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: tensorboard==2.2.0 in /opt/conda/lib/python3.7/site-packages (2.2.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (0.10.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (3.13.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.14.0)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.18.5)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.14.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (46.1.3.post20200325)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.0.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (3.2.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.7.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (0.4.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (2.23.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (0.34.2)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.32.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.14.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0) (1.2.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0) (2.9)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (2.23.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0) (3.0.1)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.14.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.14.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (46.1.3.post20200325)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (46.1.3.post20200325)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.14.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (1.14.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0) (0.2.7)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0) (3.1.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0) (46.1.3.post20200325)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.2.0) (0.4.8)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.2.0) (0.4.8)\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n\u001b[31mERROR: pytorch-lightning 0.9.0 requires tensorboard==2.2.0, but you'll have tensorboard 2.3.0 which is incompatible.\u001b[0m\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting sentence-transformers\n  Downloading sentence-transformers-0.3.8.tar.gz (66 kB)\n\u001b[K     |████████████████████████████████| 66 kB 171 kB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.45.0)\nRequirement already satisfied: torch>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.6.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.18.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.23.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.4.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.2.4)\nCollecting transformers<3.4.0,>=3.1.0\n  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n\u001b[K     |████████████████████████████████| 1.1 MB 467 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (20.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.45.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.18.5)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2020.4.4)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.0.43)\nRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.1.91)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2.23.0)\nCollecting tokenizers==0.8.1.rc2\n  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n\u001b[K     |████████████████████████████████| 3.0 MB 6.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.2.0->sentence-transformers) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.18.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.14.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.4.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.14.0)\n","name":"stdout"},{"output_type":"stream","text":"Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (0.14.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.18.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.18.5)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.45.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (0.14.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.14.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2020.4.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<3.4.0,>=3.1.0->sentence-transformers) (7.1.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2020.6.20)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.8-py3-none-any.whl size=101994 sha256=e95d477cce4ef4cff5e3aa6b378de947892c5eaee06d76fd699176f706adb70b\n  Stored in directory: /root/.cache/pip/wheels/1c/43/65/fe0f3ea9327623e749a79eb5dfad85a809c84064b1cc4682c1\nSuccessfully built sentence-transformers\nInstalling collected packages: tokenizers, transformers, sentence-transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.8.1rc1\n    Uninstalling tokenizers-0.8.1rc1:\n      Successfully uninstalled tokenizers-0.8.1rc1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 3.0.2\n    Uninstalling transformers-3.0.2:\n      Successfully uninstalled transformers-3.0.2\n\u001b[31mERROR: allennlp 1.1.0 requires transformers<3.1,>=3.0, but you'll have transformers 3.3.1 which is incompatible.\u001b[0m\nSuccessfully installed sentence-transformers-0.3.8 tokenizers-0.8.1rc2 transformers-3.3.1\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting razdel\n  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\nInstalling collected packages: razdel\nSuccessfully installed razdel-0.5.0\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting navec\n  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from navec) (1.18.5)\nInstalling collected packages: navec\nSuccessfully installed navec-0.10.0\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting slovnet\n  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n\u001b[K     |████████████████████████████████| 49 kB 125 kB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: navec in /opt/conda/lib/python3.7/site-packages (from slovnet) (0.10.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from slovnet) (1.18.5)\nRequirement already satisfied: razdel in /opt/conda/lib/python3.7/site-packages (from slovnet) (0.5.0)\nInstalling collected packages: slovnet\nSuccessfully installed slovnet-0.5.0\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\nimport tensorflow_hub as hub\nimport tensorflow_text\nimport torch\nfrom navec import Navec\nfrom razdel import sentenize, tokenize\nfrom sentence_transformers import SentenceTransformer, util, models\nfrom slovnet import Morph","execution_count":7,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.92\nqueries_path = '../input/queries/queries.json' # путь к запросам\nhandbook_path = '../input/handbook/handbook.xls' # путь к справочнику \nmodel_path_directory = '../input/pytorch-rubert/' # путь к модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.isfile('navec_news_v1_1B_250K_300d_100q.tar'):\n    !wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar\nif not os.path.isfile('slovnet_morph_news_v1.tar'):\n    !conda install -y gdown \n    !gdown https://drive.google.com/uc?id=1U4TT9cGtdYL8I0G5NSd2gCvia9wpFpDr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(queries_path) as json_file:\n    data = json.load(json_file)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"queries = [item['Item'] for project in data['Names'] for item in project['Items']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"handbook = pd.read_excel(handbook_path)\nhandbook.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"handbook.iloc[:, 2] = handbook.iloc[:, 2].fillna('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Corpus with example sentences\nhandbook_names = handbook.iloc[:, 2].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\nmorph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)\nmorph.navec(navec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RuBERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_embedding_model = models.Transformer(model_path_directory, max_seq_length=256)\npooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n\nrubert_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"handbook_rubert_embeddings = rubert_model.encode(handbook_names, convert_to_tensor=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = {'Исходный текст': [],\n           'Количество': [],\n           'Единицы измерения': [],\n           'Предлагаемый вариант': [],\n           'Коэффициент сходства, %': []}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def element_extraction(text):\n    digit_terms = re.findall('\\w*\\d*[\\.,]?\\d+\\w*', text)\n\n    chunk = []\n    for sentence in sentenize(text.lower()):\n        print(sentence)\n        tokens = [_.text for _ in tokenize(sentence.text)]\n        chunk.append(tokens)\n    markup = next(morph.map(chunk))\n    \n    nouns = []\n    adjectives = []\n    for token in markup.tokens:\n        if (token.pos == 'NOUN' or token.pos == 'PNOUN') and not(re.findall('\\d+', token.text)):\n            nouns.append(token.text)\n        if token.pos == 'ADJ' or token.pos == 'ADV':\n            adjectives.append(token.text)\n    return digit_terms, nouns, adjectives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def improved_cosine_similarity(record, addendums_coef, adj_coef):\n    digit_terms, nouns, adjectives = element_extraction(record)\n    digit_terms_encoded = rubert_model.encode(' '.join(digit_terms), convert_to_tensor=True)\n    nouns_encoded = rubert_model.encode(' '.join(nouns), convert_to_tensor=True)\n    adjectives_encoded = rubert_model.encode(' '.join(adjectives), convert_to_tensor=True)\n    \n    digits_cos_scores = util.pytorch_cos_sim(query_digit_terms_encoded, digit_terms_encoded).cpu()\n    nouns_cos_scores = util.pytorch_cos_sim(query_nouns_encoded, nouns_encoded).cpu()\n    adj_cos_scores = util.pytorch_cos_sim(query_adjectives_encoded, adjectives_encoded).cpu()\n    \n    return addendums_coef * (digits_cos_scores + nouns_cos_scores + adj_coef * adj_cos_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the closest 20 sentences of the corpus for each query sentence based on cosine similarity\ntop_k = 20\naddendums_coef = 0.1\nadj_coef = 0.8\n\nfor query in queries:\n    query_embedding = rubert_model.encode(query, convert_to_tensor=True)\n    cos_scores = util.pytorch_cos_sim(query_embedding, handbook_rubert_embeddings)[0]\n    cos_scores = cos_scores.cpu()\n    \n    top_results = torch.topk(cos_scores, k=top_k)\n    top_results_values = top_results.values.numpy()\n    top_results_indices = top_results.indices.numpy()\n\n    query_digit_terms, query_nouns, query_adjectives = element_extraction(query)\n    query_digit_terms_encoded = rubert_model.encode(' '.join(query_digit_terms), convert_to_tensor=True)\n    query_nouns_encoded = rubert_model.encode(' '.join(query_nouns), convert_to_tensor=True)\n    query_adjectives_encoded = rubert_model.encode(' '.join(query_adjectives), convert_to_tensor=True)\n         \n    top_results_values = [top_results_values[n] + improved_cosine_similarity(handbook_names[top_results_indices[n]],\n                                                                             addendums_coef,\n                                                                             adj_coef) for n in range(top_k)]\n    max_cos_indices = np.argsort(top_results_values)[::-1]\n\n    new_top_results_values = [top_results_values[n] for n in max_cos_indices][:1:]\n    top_results_indices = [top_results_indices[n] for n in max_cos_indices][:1:]\n    self_similarity = 1 + addendums_coef * (2 + adj_coef)\n    \n    similarity_coef = float(new_top_results_values[0][0][0]) / self_similarity\n\n    if similarity_coef >= threshold:\n        results['Исходный текст'].append(query)\n        results['Количество'].append(1)\n        results['Единицы измерения'].append('шт')\n        results['Предлагаемый вариант'].append(handbook_names[top_results_indices[0]])\n        results['Коэффициент сходства, %'].append(similarity_coef * 100)\n    else:\n        results['Исходный текст'].append(query)\n        results['Количество'].append(1)\n        results['Единицы измерения'].append('шт')\n        results['Предлагаемый вариант'].append('')\n        results['Коэффициент сходства, %'].append('')    \n\n# without other information","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame(results)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.to_csv('./results.csv', sep=';', encoding='utf-8-sig')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'results.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}